{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98abda8b-0ac1-40a2-9868-8b2a887f77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Feb 24 00:38:32 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10          On   | 00000000:06:00.0 Off |                    0 |\n",
      "|  0%   33C    P8    20W / 150W |      0MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "# If this doesn't work, there's no GPU available or detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01221287-6037-4ba7-b3b1-e17a7d3d2dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in ./.local/lib/python3.8/site-packages (from tensorboardX) (21.3)\n",
      "Requirement already satisfied: numpy in ./.local/lib/python3.8/site-packages (from tensorboardX) (1.23.4)\n",
      "Requirement already satisfied: protobuf<4,>=3.8.0 in /usr/lib/python3/dist-packages (from tensorboardX) (3.11.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->tensorboardX) (2.4.6)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-2.6\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting audiolm-pytorch\n",
      "  Downloading audiolm_pytorch-0.16.1-py3-none-any.whl (30 kB)\n",
      "Collecting einops>=0.6\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting local-attention>=1.6.0\n",
      "  Downloading local_attention-1.6.0-py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.8/site-packages (from audiolm-pytorch) (4.64.1)\n",
      "Collecting lion-pytorch\n",
      "  Downloading lion_pytorch-0.0.7-py3-none-any.whl (4.3 kB)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.8/site-packages (from audiolm-pytorch) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/lib/python3/dist-packages (from audiolm-pytorch) (0.22.2.post1)\n",
      "Collecting fairseq\n",
      "  Downloading fairseq-0.12.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m100.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m198.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting beartype\n",
      "  Downloading beartype-0.12.0-py3-none-any.whl (754 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m754.5/754.5 kB\u001b[0m \u001b[31m130.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting Mega-pytorch\n",
      "  Downloading Mega_pytorch-0.0.15-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: torch>=1.12 in /usr/lib/python3/dist-packages (from audiolm-pytorch) (1.12.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.16.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-0.13.1-cp38-cp38-manylinux1_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m167.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ema-pytorch\n",
      "  Downloading ema_pytorch-0.2.1-py3-none-any.whl (4.4 kB)\n",
      "Collecting vector-quantize-pytorch>=0.10.15\n",
      "  Downloading vector_quantize_pytorch-1.0.4-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from accelerate->audiolm-pytorch) (5.5.1)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from accelerate->audiolm-pytorch) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.local/lib/python3.8/site-packages (from accelerate->audiolm-pytorch) (1.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.8/site-packages (from accelerate->audiolm-pytorch) (21.3)\n",
      "Requirement already satisfied: cffi in /usr/lib/python3/dist-packages (from fairseq->audiolm-pytorch) (1.14.0)\n",
      "Requirement already satisfied: cython in /usr/lib/python3/dist-packages (from fairseq->audiolm-pytorch) (0.29.14)\n",
      "Collecting bitarray\n",
      "  Downloading bitarray-2.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (271 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.8/271.8 kB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting hydra-core<1.1,>=1.0.7\n",
      "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2022.10.31-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 kB\u001b[0m \u001b[31m116.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sacrebleu>=1.4.12\n",
      "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting omegaconf<2.1\n",
      "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
      "Collecting torch>=1.12\n",
      "  Downloading torch-1.13.1-cp38-cp38-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m130.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in ./.local/lib/python3.8/site-packages (from torch>=1.12->audiolm-pytorch) (4.4.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.12->audiolm-pytorch) (45.2.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.12->audiolm-pytorch) (0.34.2)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.8/site-packages (from Mega-pytorch->audiolm-pytorch) (1.9.3)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.8/site-packages (from transformers->audiolm-pytorch) (2.28.1)\n",
      "Collecting huggingface-hub<1.0,>=0.11.0\n",
      "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers->audiolm-pytorch) (3.0.12)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
      "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting importlib-resources\n",
      "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging>=20.0->accelerate->audiolm-pytorch) (2.4.6)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: lxml in /usr/lib/python3/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch) (4.5.0)\n",
      "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu>=1.4.12->fairseq->audiolm-pytorch) (0.4.3)\n",
      "Collecting tabulate>=0.8.9\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers->audiolm-pytorch) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./.local/lib/python3.8/site-packages (from requests->transformers->audiolm-pytorch) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers->audiolm-pytorch) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers->audiolm-pytorch) (2.8)\n",
      "Collecting zipp>=3.1.0\n",
      "  Downloading zipp-3.14.0-py3-none-any.whl (6.7 kB)\n",
      "Building wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=71fc43936fd7cfaed0800852bdd615788d4e11d835211c87b01cdf9a9766e967\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/34/d7/fe/a833ceccaee881c6f8cd49985ee4285bf94c5cf2c66ea5db68\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: tokenizers, sentencepiece, bitarray, antlr4-python3-runtime, zipp, tabulate, regex, portalocker, omegaconf, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, einops, beartype, sacrebleu, nvidia-cudnn-cu11, importlib-resources, huggingface-hub, transformers, torch, hydra-core, vector-quantize-pytorch, torchaudio, Mega-pytorch, local-attention, lion-pytorch, ema-pytorch, accelerate, fairseq, audiolm-pytorch\n",
      "Successfully installed Mega-pytorch-0.0.15 accelerate-0.16.0 antlr4-python3-runtime-4.8 audiolm-pytorch-0.16.1 beartype-0.12.0 bitarray-2.7.3 einops-0.6.0 ema-pytorch-0.2.1 fairseq-0.12.2 huggingface-hub-0.12.1 hydra-core-1.0.7 importlib-resources-5.12.0 lion-pytorch-0.0.7 local-attention-1.6.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 omegaconf-2.0.6 portalocker-2.7.0 regex-2022.10.31 sacrebleu-2.3.1 sentencepiece-0.1.97 tabulate-0.9.0 tokenizers-0.13.2 torch-1.13.1 torchaudio-0.13.1 transformers-4.26.1 vector-quantize-pytorch-1.0.4 zipp-3.14.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX\n",
    "!pip install audiolm-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d5e4261-d457-4f53-9353-9fe1539dd90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with dataset of 2567 samples and validating with randomly splitted 136 samples\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "do you want to clear previous experiment checkpoints and results? (y/n)  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: soundstream total loss: 1028670.922, soundstream recon loss: 1.146 | discr (scale 1) loss: 2.003 | discr (scale 0.5) loss: 2.001 | discr (scale 0.25) loss: 2.000\n",
      "0: saving to results\n",
      "0: saving model to results\n",
      "1: soundstream total loss: 982905.281, soundstream recon loss: 1.053 | discr (scale 1) loss: 1.982 | discr (scale 0.5) loss: 1.993 | discr (scale 0.25) loss: 1.996\n",
      "2: soundstream total loss: 820282.883, soundstream recon loss: 0.813 | discr (scale 1) loss: 1.951 | discr (scale 0.5) loss: 1.985 | discr (scale 0.25) loss: 1.981\n",
      "3: soundstream total loss: 280241.453, soundstream recon loss: 0.341 | discr (scale 1) loss: 1.931 | discr (scale 0.5) loss: 1.983 | discr (scale 0.25) loss: 1.975\n",
      "4: soundstream total loss: 114009.168, soundstream recon loss: 0.154 | discr (scale 1) loss: 1.940 | discr (scale 0.5) loss: 1.990 | discr (scale 0.25) loss: 1.992\n",
      "4: saving to results\n",
      "4: saving model to results\n",
      "5: soundstream total loss: 61593.055, soundstream recon loss: 0.072 | discr (scale 1) loss: 1.946 | discr (scale 0.5) loss: 2.017 | discr (scale 0.25) loss: 2.033\n",
      "6: soundstream total loss: 51955.920, soundstream recon loss: 0.063 | discr (scale 1) loss: 1.978 | discr (scale 0.5) loss: 2.021 | discr (scale 0.25) loss: 2.038\n",
      "7: soundstream total loss: 34716.982, soundstream recon loss: 0.048 | discr (scale 1) loss: 1.815 | discr (scale 0.5) loss: 1.991 | discr (scale 0.25) loss: 2.013\n",
      "8: soundstream total loss: 115033.648, soundstream recon loss: 0.140 | discr (scale 1) loss: 1.981 | discr (scale 0.5) loss: 1.975 | discr (scale 0.25) loss: 1.986\n",
      "8: saving to results\n",
      "8: saving model to results\n",
      "training complete\n",
      "data_load_time: {2.331118}, train_time: {31.103945}\n"
     ]
    }
   ],
   "source": [
    "# single cell notebook to simulate a python script, so we can just train SoundStream by running the script\n",
    "\n",
    "# requires: audiolm-pytorch, tensorboardX\n",
    "\n",
    "# raise AssertionError(\"Make sure to set num train steps and how frequently to save model. right now it's very low just to test in google colab\")\n",
    "\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from audiolm_pytorch import SoundStream, SoundStreamTrainer, HubertWithKmeans, SemanticTransformer, SemanticTransformerTrainer, HubertWithKmeans, CoarseTransformer, CoarseTransformerWrapper, CoarseTransformerTrainer, FineTransformer, FineTransformerWrapper, FineTransformerTrainer, AudioLM\n",
    "from torch import nn\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import torch\n",
    "import torchaudio\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "# small clean dataset\n",
    "filename = \"dev-clean\"\n",
    "filename_targz = filename + \".tar.gz\"\n",
    "url = f\"https://us.openslr.org/resources/12/{filename_targz}\"\n",
    "if not os.path.isfile(filename_targz):\n",
    "  urllib.request.urlretrieve(url, filename_targz)\n",
    "if not os.path.isdir(filename):\n",
    "  # open file\n",
    "  with tarfile.open(filename_targz) as t:\n",
    "    t.extractall(filename)\n",
    "dataset_folder = filename # update dataset_folder so we use the right dataset\n",
    "\n",
    "# remove old results files if they're around\n",
    "if os.path.isdir(\"results\"):\n",
    "  shutil.rmtree(\"results\")\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "  with record_function(\"data_load\"):\n",
    "    soundstream = SoundStream(\n",
    "        codebook_size = 1024,\n",
    "        rq_num_quantizers = 12,\n",
    "        attn_window_size = 128,       # local attention receptive field at bottleneck\n",
    "        attn_depth = 2                # 2 local attention transformer blocks - the soundstream folks were not experts with attention, so i took the liberty to add some. encodec went with lstms, but attention should be better\n",
    "    )\n",
    "    \n",
    "    before_trainer_load = datetime.datetime.now()\n",
    "    trainer = SoundStreamTrainer(\n",
    "        soundstream,\n",
    "        folder = dataset_folder,\n",
    "        batch_size = 2,\n",
    "        grad_accum_every = 8,\n",
    "        data_max_length_seconds = 1,\n",
    "        num_train_steps = 9,\n",
    "        save_results_every = 4,\n",
    "        save_model_every = 4,\n",
    "    ).cuda()\n",
    "    before_train = datetime.datetime.now()\n",
    "    with record_function(\"train\"):\n",
    "      trainer.train()\n",
    "\n",
    "      data_load_time = {(before_train - before_trainer_load).total_seconds()}\n",
    "      train_time = {(datetime.datetime.now() - before_train).total_seconds()}\n",
    "      print(f\"data_load_time: {data_load_time}, train_time: {train_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5e47a48-9095-47f2-8eb3-cafba978139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \\n                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \\n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \\n                                              data_load         4.81%        2.266s        71.49%       33.681s       33.681s       0.000us         0.00%        5.161s        5.161s             1  \\n                                                  train        40.79%       19.217s        66.02%       31.104s       31.104s       0.000us         0.00%        5.125s        5.125s             1  \\nautograd::engine::evaluate_function: ConvolutionBack...         0.66%     310.281ms        14.17%        6.674s     268.685us       0.000us         0.00%        4.895s     197.069us         24840  \\n                             aten::convolution_backward         7.29%        3.434s        12.34%        5.816s     234.134us        4.025s        23.61%        4.610s     185.589us         24840  \\n                                   ConvolutionBackward0         0.26%     124.280ms        12.60%        5.935s     238.940us       0.000us         0.00%        4.606s     185.428us         24840  \\n                                     aten::_convolution         0.62%     292.675ms         8.28%        3.903s     125.778us       0.000us         0.00%        3.625s     116.805us         31032  \\n                                      aten::convolution         0.40%     186.274ms         8.67%        4.086s     131.660us       0.000us         0.00%        3.607s     116.249us         31032  \\n                                aten::cudnn_convolution         4.52%        2.128s         6.06%        2.856s      93.851us        3.215s        18.86%        3.277s     107.682us         30432  \\n                                            aten::copy_         1.70%     799.369ms         4.18%        1.970s      12.638us        2.772s        16.26%        2.772s      17.778us        155905  \\nvoid at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us        1.837s        10.78%        1.837s      16.991us        108129  \\n-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \\nSelf CPU time total: 47.115s\\nSelf CUDA time total: 17.047s\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10)\n",
    "# prof.key_averages().table(row_limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cc37bf-564c-4f66-bb5f-e1e6765dc045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mType:\u001b[0m           ProfilerActivity\n",
       "\u001b[0;31mString form:\u001b[0m    ProfilerActivity.CUDA\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Members:\n",
       "\n",
       "CPU\n",
       "\n",
       "CUDA\n",
       "\u001b[0;31mInit docstring:\u001b[0m __init__(self: torch._C._profiler.ProfilerActivity, value: int) -> None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??ProfilerActivity.CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b54b5-3470-4657-8747-0d194b2a348f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
